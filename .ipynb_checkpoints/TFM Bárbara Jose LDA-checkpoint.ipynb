{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFM: versión LDA  \n",
    "\n",
    "En esta versión del documento, vamos a tratar de analizar los tweets de la RAE de manera cuantitativa y clasificativa haciendo uso de la herramienta LDA y la librería **PANDAS**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "---\n",
    "Primero debemos importar los tweets de un documento *excel* o *csv*:\n",
    "``` python \n",
    "\n",
    "    # Importing modules\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    \n",
    "    # Read data into papers\n",
    "    papers = pd.read_csv('../../tweets.csv') #ruta\n",
    "    \n",
    "    # Print head\n",
    "    papers.head()\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>userid</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>symbols</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>reply</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>quote</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>RT</th>\n",
       "      <th>RT_source</th>\n",
       "      <th>nRTin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1334077182629601286</td>\n",
       "      <td>@sare621107 #RAEconsultas Lo que indica el «DL...</td>\n",
       "      <td>350411337</td>\n",
       "      <td>RAEinforma</td>\n",
       "      <td>2020-12-02T10:09:20.000Z</td>\n",
       "      <td>&lt;a href=\"https://www.hootsuite.com\" rel=\"nofol...</td>\n",
       "      <td>[{\"text\":\"RAEconsultas\",\"indices\":[12,25]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"screen_name\":\"sare621107\",\"name\":\"Ernesto S...</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.198385e+08</td>\n",
       "      <td>1.333900e+18</td>\n",
       "      <td>sare621107</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1334077668422201344</td>\n",
       "      <td>@kunaino #RAEconsultas En efecto, debe de trat...</td>\n",
       "      <td>350411337</td>\n",
       "      <td>RAEinforma</td>\n",
       "      <td>2020-12-02T10:11:16.000Z</td>\n",
       "      <td>&lt;a href=\"https://www.hootsuite.com\" rel=\"nofol...</td>\n",
       "      <td>[{\"text\":\"RAEconsultas\",\"indices\":[9,22]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"screen_name\":\"kunaino\",\"name\":\"Kuña\",\"id\":4...</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4.916835e+08</td>\n",
       "      <td>1.333912e+18</td>\n",
       "      <td>kunaino</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1334078266215452672</td>\n",
       "      <td>@so3ndok #RAEconsultas Sí, uno de los usos de ...</td>\n",
       "      <td>350411337</td>\n",
       "      <td>RAEinforma</td>\n",
       "      <td>2020-12-02T10:13:39.000Z</td>\n",
       "      <td>&lt;a href=\"https://www.hootsuite.com\" rel=\"nofol...</td>\n",
       "      <td>[{\"text\":\"RAEconsultas\",\"indices\":[9,22]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"screen_name\":\"so3ndok\",\"name\":\"Tomás Moi\",\"...</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1.332657e+18</td>\n",
       "      <td>1.333928e+18</td>\n",
       "      <td>so3ndok</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1334078499112542211</td>\n",
       "      <td>@JorgeBorlandL #RAEconsultas Lo sentimos, pero...</td>\n",
       "      <td>350411337</td>\n",
       "      <td>RAEinforma</td>\n",
       "      <td>2020-12-02T10:14:34.000Z</td>\n",
       "      <td>&lt;a href=\"https://www.hootsuite.com\" rel=\"nofol...</td>\n",
       "      <td>[{\"text\":\"RAEconsultas\",\"indices\":[15,28]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"screen_name\":\"JorgeBorlandL\",\"name\":\"G2 Bol...</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2.252063e+09</td>\n",
       "      <td>1.333952e+18</td>\n",
       "      <td>JorgeBorlandL</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1334034386526867458</td>\n",
       "      <td>@jandrote #RAEconsultas La grafía del gerundio...</td>\n",
       "      <td>350411337</td>\n",
       "      <td>RAEinforma</td>\n",
       "      <td>2020-12-02T07:19:17.000Z</td>\n",
       "      <td>&lt;a href=\"https://www.hootsuite.com\" rel=\"nofol...</td>\n",
       "      <td>[{\"text\":\"RAEconsultas\",\"indices\":[10,23]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"screen_name\":\"jandrote\",\"name\":\"josue vega\"...</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1.240261e+08</td>\n",
       "      <td>1.333980e+18</td>\n",
       "      <td>jandrote</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id                                               text  \\\n",
       "0  1334077182629601286  @sare621107 #RAEconsultas Lo que indica el «DL...   \n",
       "1  1334077668422201344  @kunaino #RAEconsultas En efecto, debe de trat...   \n",
       "2  1334078266215452672  @so3ndok #RAEconsultas Sí, uno de los usos de ...   \n",
       "3  1334078499112542211  @JorgeBorlandL #RAEconsultas Lo sentimos, pero...   \n",
       "4  1334034386526867458  @jandrote #RAEconsultas La grafía del gerundio...   \n",
       "\n",
       "      userid screen_name                created_at  \\\n",
       "0  350411337  RAEinforma  2020-12-02T10:09:20.000Z   \n",
       "1  350411337  RAEinforma  2020-12-02T10:11:16.000Z   \n",
       "2  350411337  RAEinforma  2020-12-02T10:13:39.000Z   \n",
       "3  350411337  RAEinforma  2020-12-02T10:14:34.000Z   \n",
       "4  350411337  RAEinforma  2020-12-02T07:19:17.000Z   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"https://www.hootsuite.com\" rel=\"nofol...   \n",
       "1  <a href=\"https://www.hootsuite.com\" rel=\"nofol...   \n",
       "2  <a href=\"https://www.hootsuite.com\" rel=\"nofol...   \n",
       "3  <a href=\"https://www.hootsuite.com\" rel=\"nofol...   \n",
       "4  <a href=\"https://www.hootsuite.com\" rel=\"nofol...   \n",
       "\n",
       "                                      hashtags symbols  \\\n",
       "0  [{\"text\":\"RAEconsultas\",\"indices\":[12,25]}]      []   \n",
       "1   [{\"text\":\"RAEconsultas\",\"indices\":[9,22]}]      []   \n",
       "2   [{\"text\":\"RAEconsultas\",\"indices\":[9,22]}]      []   \n",
       "3  [{\"text\":\"RAEconsultas\",\"indices\":[15,28]}]      []   \n",
       "4  [{\"text\":\"RAEconsultas\",\"indices\":[10,23]}]      []   \n",
       "\n",
       "                                       user_mentions lang  ...  coordinates  \\\n",
       "0  [{\"screen_name\":\"sare621107\",\"name\":\"Ernesto S...   es  ...          NaN   \n",
       "1  [{\"screen_name\":\"kunaino\",\"name\":\"Kuña\",\"id\":4...   es  ...          NaN   \n",
       "2  [{\"screen_name\":\"so3ndok\",\"name\":\"Tomás Moi\",\"...   es  ...          NaN   \n",
       "3  [{\"screen_name\":\"JorgeBorlandL\",\"name\":\"G2 Bol...   es  ...          NaN   \n",
       "4  [{\"screen_name\":\"jandrote\",\"name\":\"josue vega\"...   es  ...          NaN   \n",
       "\n",
       "   reply  in_reply_to_user_id_str  in_reply_to_status_id_str  \\\n",
       "0   True             3.198385e+08               1.333900e+18   \n",
       "1   True             4.916835e+08               1.333912e+18   \n",
       "2   True             1.332657e+18               1.333928e+18   \n",
       "3   True             2.252063e+09               1.333952e+18   \n",
       "4   True             1.240261e+08               1.333980e+18   \n",
       "\n",
       "   in_reply_to_screen_name  quote  quoted_status_id_str     RT RT_source nRTin  \n",
       "0               sare621107  False                   NaN  False       NaN   0.0  \n",
       "1                  kunaino  False                   NaN  False       NaN   0.0  \n",
       "2                  so3ndok  False                   NaN  False       NaN   0.0  \n",
       "3            JorgeBorlandL  False                   NaN  False       NaN   0.0  \n",
       "4                 jandrote  False                   NaN  False       NaN   2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#poner código válido aquí:\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "papers = pd.read_csv('tuits.csv')\n",
    "\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "---\n",
    "El siguiente paso es limpiar los datos. Eliminaremos las columnas que no nos interesan del documento cargado. Además, se imprimirá la primera fila del documento como título de las otras:\n",
    "``` python\n",
    "\n",
    "    # Remove the columns\n",
    "    papers = papers.drop(columns=['id', 'event_type', 'pdf_name'], axis=1).sample(100)\n",
    "    \n",
    "    # Print out the first rows of papers\n",
    "    papers.head()\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5855</th>\n",
       "      <td>@Brenaidan #RAEconsultas Sobre la categoría gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>@GB46754202 #RAEconsultas Ambas son válidas; l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899</th>\n",
       "      <td>Cala</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "5855  @Brenaidan #RAEconsultas Sobre la categoría gr...\n",
       "5698                                                NaN\n",
       "2336                                                NaN\n",
       "3193  @GB46754202 #RAEconsultas Ambas son válidas; l...\n",
       "6899                                               Cala"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#poner código válido aquí:\n",
    "#limpiar columnas para obtener solo la columna de tweets \n",
    "papers = papers.drop(columns= ['_id', 'screen_name', 'favorite_count', 'coordinates', 'reply', 'in_reply_to_status_id_str', 'in_reply_to_screen_name', 'quote','quoted_status_id_str', 'RT', 'RT_source', 'nRTin','userid', 'created_at', 'source', 'hashtags','symbols', 'user_mentions', 'lang','quote_count','reply_count', 'retweet_count', 'in_reply_to_user_id_str'], axis=1).sample(100)\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing\n",
    "---\n",
    "En este apartado vamos a limpiar los signos de puntuación que no nos interesen. En este ejemplo se aprecia el borrado de **puntuación**, **mayúsculas** y la **primera fila** del la hoja de datos, pero se pueden añadir, por ejemplo, **_stopwords_**:\n",
    "``` python\n",
    "\n",
    "    # Load the regular expression library\n",
    "    import re\n",
    "    \n",
    "    # Remove punctuation\n",
    "    papers['paper_text_processed'] = \\\n",
    "    papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "    \n",
    "    # Convert the titles to lowercase\n",
    "    papers['paper_text_processed'] = \\\n",
    "    papers['paper_text_processed'].map(lambda x: x.lower())\n",
    "    \n",
    "    # Print out the first rows of papers\n",
    "    papers['paper_text_processed'].head()\n",
    "\n",
    "    ```\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-ed33e956de7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpapers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpapers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[,\\.!?#]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpapers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpapers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "#poner código válido aquí:\n",
    "import re \n",
    "papers['text'] = \\\n",
    "papers['text'].map(lambda x: re.sub('[,\\.!?#]', '', x))\n",
    "papers['text'] = \\\n",
    "papers['text'].map(lambda x: x.lower())\n",
    "papers['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the visual *cloud*\n",
    "---\n",
    "En este apartado vamos a crear una imagen visual que nos indique a través de su tamaño, cuales son las palabras que mas aparecen en nuestro corpus. Esto no tiene unicamente una función decorativa, sino que podemos :\n",
    "``` python\n",
    "\n",
    "    # Import the wordcloud library\n",
    "    from wordcloud import WordCloud\n",
    "    \n",
    "    # Join the different processed titles together.\n",
    "    long_string = ','.join(list(papers['paper_text_processed'].values))\n",
    "    \n",
    "    # Create a WordCloud object\n",
    "    wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color='steelblue')\n",
    "    \n",
    "    # Generate a word cloud\n",
    "    wordcloud.generate(long_string)\n",
    "    \n",
    "    # Visualize the word cloud\n",
    "    wordcloud.to_image()\n",
    "\n",
    "    ```\n",
    "    \n",
    "<img src=\"cloud.jpg\" width=\"50%\" height=\"50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poner código válido aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for LDA\n",
    "---\n",
    "Hay que transformar los datos para que sirvan como input en un **modelo de entrenamiento LDA**. Se tokeniza y se eliminan las _stopwords_, si es que no se ha hecho antes:\n",
    "``` python\n",
    "\n",
    "    import gensim\n",
    "    from gensim.utils import simple_preprocess\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "    \n",
    "    def sent_to_words(sentences):\n",
    "        for sentence in sentences:\n",
    "            # deacc=True removes punctuations\n",
    "            yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "            \n",
    "    def remove_stopwords(texts):\n",
    "        return [[word for word in simple_preprocess(str(doc)) \n",
    "                 if word not in stop_words] for doc in texts]\n",
    "    \n",
    "    data = papers.paper_text_processed.values.tolist()\n",
    "    data_words = list(sent_to_words(data))\n",
    "    \n",
    "    # remove stop words\n",
    "    data_words = remove_stopwords(data_words)\n",
    "    \n",
    "    print(data_words[:1][0][:30])\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poner código válido aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de entrenamiento LDA\n",
    "---\n",
    "En esta parte indicamos a LDA en cuantas categorías se va a clasificar el corpus. En el siguiente ejemplo, vemos que son 10. Como resultado, obtendremos las diez categorias con las palabras que mayor número de apariciones tengan:\n",
    "``` python\n",
    "\n",
    "    from pprint import pprint\n",
    "    \n",
    "    # number of topics\n",
    "    num_topics = 10\n",
    "    \n",
    "    # Build LDA model\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics)\n",
    "    \n",
    "    # Print the Keyword in the 10 topics\n",
    "    pprint(lda_model.print_topics())\n",
    "    doc_lda = lda_model[corpus]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poner código válido aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos\n",
    "---\n",
    "En esta seción obtenemos una representación gráfica de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poner código válido aquí:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
